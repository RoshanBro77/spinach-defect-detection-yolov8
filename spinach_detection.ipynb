{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 ‚Äî Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "print(f'Python  : {platform.python_version()}')\n",
    "print(f'PyTorch : {torch.__version__}')\n",
    "print(f'Machine : {platform.machine()} ‚Äî {platform.system()}')\n",
    "print()\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "    print('‚úÖ Apple MPS (M2 GPU) ‚Äî training will use your M2 chip')\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    print('‚úÖ CUDA GPU available')\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    print('‚ö†Ô∏è  No GPU found ‚Äî using CPU')\n",
    "\n",
    "print(f'\\nüñ•Ô∏è  Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 ‚Äî Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# ‚îÄ‚îÄ Paths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "BASE_DIR     = Path.cwd()                   \n",
    "DATASET_YAML = BASE_DIR / 'dataset.yaml'     \n",
    "SPLITS_DIR   = BASE_DIR / 'data' / 'splits'\n",
    "RUNS_DIR     = BASE_DIR / 'runs'\n",
    "REPORTS_DIR  = BASE_DIR / 'reports'\n",
    "\n",
    "MODEL_SIZE  = 'yolov8n.pt'\n",
    "MODEL_NAME  = 'spinach_v1'\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Training ‚Äî FAST settings for M2 Air ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "EPOCHS      = 20      # 20 is enough for a first run with pretrained weights\n",
    "BATCH_SIZE  = 32      # 32 is fine on 16GB M2 ‚Äî halves training time vs batch=8\n",
    "IMAGE_SIZE  = 416     # smaller than 640, still good quality, faster\n",
    "PATIENCE    = 7       # stop early if no improvement for 7 epochs\n",
    "WORKERS     = 0       \n",
    "AMP         = False   # MUST be False on MPS \n",
    "\n",
    "# ‚îÄ‚îÄ Classes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "CLASS_NAMES = ['spinach_leaf','stem','GOOD','YELLOW','HOLE','TRACK','WSPOT','FSPOT']\n",
    "CLASS_COLORS = [\n",
    "    (46,125,50),   # spinach_leaf\n",
    "    (139,90,43),   # stem\n",
    "    (76,175,80),   # GOOD\n",
    "    (255,193,7),   # YELLOW\n",
    "    (244,67,54),   # HOLE\n",
    "    (255,87,34),   # TRACK\n",
    "    (156,39,176),  # WSPOT\n",
    "    (63,81,181),   # FSPOT\n",
    "]\n",
    "\n",
    "# ‚îÄ‚îÄ Verify ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "if DATASET_YAML.exists():\n",
    "    print(f'dataset.yaml found')\n",
    "    print(f'Config ready')\n",
    "    print(f'   Model      : {MODEL_SIZE} (nano ‚Äî fast mode)')\n",
    "    print(f'   Device     : {DEVICE}')\n",
    "    print(f'   Epochs     : {EPOCHS}')\n",
    "    print(f'   Batch      : {BATCH_SIZE}')\n",
    "    print(f'   Image size : {IMAGE_SIZE}px')\n",
    "    print(f'   Est. time  : 20‚Äì35 minutes')\n",
    "else:\n",
    "    print(f'Dataset.yaml not found at {DATASET_YAML}')\n",
    "    print('   Run: python 01_prepare_dataset.py first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 ‚Äî Check the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('üìä Dataset Check')\n",
    "print('‚îÄ' * 45)\n",
    "all_ok = True\n",
    "for split in ['train', 'val', 'test']:\n",
    "    imgs = len(list((SPLITS_DIR / split / 'images').glob('*.*')))\n",
    "    lbls = len(list((SPLITS_DIR / split / 'labels').glob('*.txt')))\n",
    "    ok   = '‚úÖ' if imgs > 0 else '‚ùå'\n",
    "    print(f'  {ok} {split:<6} : {imgs} images | {lbls} labels')\n",
    "    if imgs == 0:\n",
    "        all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    # Class breakdown for training set\n",
    "    counts = Counter()\n",
    "    for f in (SPLITS_DIR / 'train' / 'labels').glob('*.txt'):\n",
    "        for line in f.read_text().splitlines():\n",
    "            parts = line.strip().split()\n",
    "            if parts:\n",
    "                counts[int(parts[0])] += 1\n",
    "    print(f'\\n  Training set class breakdown:')\n",
    "    for i, name in enumerate(CLASS_NAMES):\n",
    "        n = counts.get(i, 0)\n",
    "        print(f'    [{i}] {name:<15} {n:>5} annotations')\n",
    "    print('\\n  ‚úÖ Ready to train!')\n",
    "else:\n",
    "    print('\\n  ‚ùå Missing data. Run 01_prepare_dataset.py first.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 ‚Äî Preview Training Images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def draw_boxes(img_path, lbl_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    if lbl_path.exists():\n",
    "        for line in lbl_path.read_text().splitlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                cls = int(parts[0])\n",
    "                cx, cy, bw, bh = float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "                x1 = int((cx - bw/2) * w)\n",
    "                y1 = int((cy - bh/2) * h)\n",
    "                x2 = int((cx + bw/2) * w)\n",
    "                y2 = int((cy + bh/2) * h)\n",
    "                col = CLASS_COLORS[cls % len(CLASS_COLORS)]\n",
    "                cv2.rectangle(img, (x1,y1), (x2,y2), col, 3)\n",
    "                label = CLASS_NAMES[cls] if cls < len(CLASS_NAMES) else str(cls)\n",
    "                (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(img, (x1, max(0,y1-22)), (x1+tw+4, y1), col, -1)\n",
    "                cv2.putText(img, label, (x1+2, max(15, y1-5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "    return img\n",
    "\n",
    "train_imgs = list((SPLITS_DIR / 'train' / 'images').glob('*.*'))\n",
    "\n",
    "if not train_imgs:\n",
    "    print('No training images found ‚Äî check that 01_prepare_dataset.py ran successfully.')\n",
    "else:\n",
    "    sample = random.sample(train_imgs, min(9, len(train_imgs)))\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 13))\n",
    "\n",
    "    for ax, img_path in zip(axes.flatten(), sample):\n",
    "        lbl_path = SPLITS_DIR / 'train' / 'labels' / (img_path.stem + '.txt')\n",
    "        img = draw_boxes(img_path, lbl_path)\n",
    "        if img is not None:\n",
    "            ax.imshow(img)\n",
    "            cls_ids = []\n",
    "            if lbl_path.exists():\n",
    "                for line in lbl_path.read_text().splitlines():\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        cls_ids.append(CLASS_NAMES[int(parts[0])])\n",
    "            ax.set_title(', '.join(set(cls_ids)) if cls_ids else 'no label', fontsize=9, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Sample Training Images', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_DIR / 'sample_training_images.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'Saved {len(sample)} sample images to reports/sample_training_images.png')\n",
    "    print('Boxes should be visible on each image with class names shown above them.')\n",
    "    print('If the box covers the whole image ‚Äî that is normal for this dataset format.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 ‚Äî Train\n",
    "\n",
    "This will take around 20‚Äì35 minutes on an M2 MacBook Air.\n",
    "Plug in your charger and leave it running ‚Äî the best weights are saved automatically to `runs/spinach_v1/weights/best.pt`.\n",
    "If you need to rerun this cell, just run it again ‚Äî it overwrites the previous output automatically.\n",
    "To keep a previous run alongside a new one, change `MODEL_NAME` to `spinach_v2` in Cell 2 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def draw_boxes(img_path, lbl_path):\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    if lbl_path.exists():\n",
    "        for line in lbl_path.read_text().splitlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                cls = int(parts[0])\n",
    "                cx, cy, bw, bh = float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4])\n",
    "                x1 = int((cx - bw/2) * w)\n",
    "                y1 = int((cy - bh/2) * h)\n",
    "                x2 = int((cx + bw/2) * w)\n",
    "                y2 = int((cy + bh/2) * h)\n",
    "                col = CLASS_COLORS[cls % len(CLASS_COLORS)]\n",
    "                cv2.rectangle(img, (x1,y1), (x2,y2), col, 3)\n",
    "                label = CLASS_NAMES[cls] if cls < len(CLASS_NAMES) else str(cls)\n",
    "                # Background rectangle for text readability\n",
    "                (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(img, (x1, max(0,y1-22)), (x1+tw+4, y1), col, -1)\n",
    "                cv2.putText(img, label, (x1+2, max(15, y1-5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "    return img\n",
    "\n",
    "train_imgs = list((SPLITS_DIR / 'train' / 'images').glob('*.*'))\n",
    "\n",
    "if not train_imgs:\n",
    "    print('No training images found. Run 01_prepare_dataset.py first.')\n",
    "else:\n",
    "    sample = random.sample(train_imgs, min(9, len(train_imgs)))\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 13))\n",
    "\n",
    "    for ax, img_path in zip(axes.flatten(), sample):\n",
    "        lbl_path = SPLITS_DIR / 'train' / 'labels' / (img_path.stem + '.txt')\n",
    "        img = draw_boxes(img_path, lbl_path)\n",
    "        if img is not None:\n",
    "            ax.imshow(img)\n",
    "            # Show class name from label file\n",
    "            cls_ids = []\n",
    "            if lbl_path.exists():\n",
    "                for line in lbl_path.read_text().splitlines():\n",
    "                    parts = line.strip().split()\n",
    "                    if parts:\n",
    "                        cls_ids.append(CLASS_NAMES[int(parts[0])])\n",
    "            title = ', '.join(set(cls_ids)) if cls_ids else 'no label'\n",
    "            ax.set_title(title, fontsize=9, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Sample Training Images ‚Äî Verify Before Training', fontsize=13, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_DIR / 'sample_training_images.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f'Showing {len(sample)} random training images')\n",
    "    print(f'   Saved to: reports/sample_training_images.png')\n",
    "    print()\n",
    "    print('What to check:')\n",
    "    print('  Images show spinach/leaves')\n",
    "    print('  Coloured boxes are drawn on the images')\n",
    "    print('  Class labels match what you see in the image')\n",
    "    print('  If boxes cover the entire image ‚Äî that is expected (classification‚Üídetection conversion)')\n",
    "    print('  If no boxes appear ‚Äî check your labels folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 ‚Äî Evaluate on Test Set\n",
    "\n",
    "Runs the trained model against images it has never seen before (the held-out test set).\n",
    "This gives a fair picture of how well it actually generalises.\n",
    "Any class showing a warning here is worth looking into ‚Äî see Cell 9 for options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "print('üöÄ Starting training...')\n",
    "print(f'   Model      : {MODEL_SIZE}')\n",
    "print(f'   Device     : {DEVICE}')\n",
    "print(f'   Epochs     : {EPOCHS}')\n",
    "print(f'   Batch      : {BATCH_SIZE}')\n",
    "print(f'   Image size : {IMAGE_SIZE}')\n",
    "print(f'   Early stop : after {PATIENCE} epochs no improvement')\n",
    "print()\n",
    "\n",
    "model = YOLO(MODEL_SIZE)   # loads pretrained nano weights from COCO\n",
    "\n",
    "results = model.train(\n",
    "    # ‚îÄ‚îÄ Dataset ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    data          = str(DATASET_YAML),\n",
    "    # ‚îÄ‚îÄ Hardware ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    device        = DEVICE,\n",
    "    workers       = WORKERS,       \n",
    "    amp           = AMP,           \n",
    "    # ‚îÄ‚îÄ Training ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    epochs        = EPOCHS,\n",
    "    batch         = BATCH_SIZE,\n",
    "    imgsz         = IMAGE_SIZE,\n",
    "    patience      = PATIENCE,\n",
    "    # ‚îÄ‚îÄ Learning rate ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    lr0           = 0.01,\n",
    "    lrf           = 0.001,\n",
    "    warmup_epochs = 3,\n",
    "    # ‚îÄ‚îÄ Built-in augmentation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mosaic        = 1.0,\n",
    "    degrees       = 15.0,\n",
    "    fliplr        = 0.5,\n",
    "    flipud        = 0.1,\n",
    "    hsv_h         = 0.015,\n",
    "    hsv_s         = 0.7,\n",
    "    hsv_v         = 0.4,\n",
    "    # ‚îÄ‚îÄ Output ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    project       = str(RUNS_DIR),\n",
    "    name          = MODEL_NAME,\n",
    "    save          = True,\n",
    "    plots         = True,\n",
    "    exist_ok      = True,          # overwrites previous run ‚Äî no need to delete\n",
    ")\n",
    "\n",
    "BEST_MODEL = RUNS_DIR / MODEL_NAME / 'weights' / 'best.pt'\n",
    "print()\n",
    "print('=' * 50)\n",
    "print('Training complete!')\n",
    "print(f'   Best model saved : {BEST_MODEL}')\n",
    "print('   Next: run Cell 5 to evaluate')\n",
    "print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 ‚Äî Training Curves \n",
    "\n",
    "Plots the loss and mAP over each epoch. Useful for checking if the model trained properly.\n",
    "Loss should decrease over time and mAP should increase ‚Äî if they look erratic something went wrong.\n",
    "The chart is also saved to `reports/training_curves.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "BEST_MODEL = RUNS_DIR / MODEL_NAME / 'weights' / 'best.pt'\n",
    "\n",
    "if not BEST_MODEL.exists():\n",
    "    print(f'Model not found. Run Cell 4 first.')\n",
    "else:\n",
    "    print(f'Loading: {BEST_MODEL}')\n",
    "    eval_model = YOLO(str(BEST_MODEL))\n",
    "\n",
    "    print('\\nüîç Evaluating on test set...')\n",
    "    metrics = eval_model.val(\n",
    "        data     = str(DATASET_YAML),\n",
    "        split    = 'test',\n",
    "        imgsz    = IMAGE_SIZE,\n",
    "        conf     = 0.25,\n",
    "        iou      = 0.5,\n",
    "        device   = DEVICE,\n",
    "        workers  = 0,\n",
    "        plots    = True,\n",
    "        project  = str(RUNS_DIR),\n",
    "        name     = MODEL_NAME + '_eval',\n",
    "        exist_ok = True,\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print('=' * 50)\n",
    "    print('TEST SET RESULTS')\n",
    "    print('=' * 50)\n",
    "    print(f'  mAP@0.5      : {metrics.box.map50:.4f}   (target ‚â• 0.60 for nano)')\n",
    "    print(f'  mAP@0.5:0.95 : {metrics.box.map:.4f}   (target ‚â• 0.40)')\n",
    "    print(f'  Precision    : {metrics.box.mp:.4f}   (target ‚â• 0.70)')\n",
    "    print(f'  Recall       : {metrics.box.mr:.4f}   (target ‚â• 0.65)')\n",
    "    print('=' * 50)\n",
    "\n",
    "    print('\\nPer-class AP@0.5:')\n",
    "    print('‚îÄ' * 45)\n",
    "    weak = []\n",
    "    for i, (name, ap) in enumerate(zip(CLASS_NAMES, metrics.box.ap50)):\n",
    "        flag = '‚úÖ' if ap >= 0.50 else '‚ö†Ô∏è '\n",
    "        print(f'  {flag} [{i}] {name:<15} {ap:.4f}')\n",
    "        if ap < 0.50:\n",
    "            weak.append(name)\n",
    "\n",
    "    print()\n",
    "    if weak:\n",
    "        print(f'  ‚ö†Ô∏è  Weak classes (AP < 0.50): {\", \".join(weak)}')\n",
    "        print('     ‚Üí Run Cell 8 (improve) or upgrade to yolov8s in Cell 2')\n",
    "    else:\n",
    "        print('   All classes above 0.50 ‚Äî good result for nano model!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 ‚Äî Confusion Matrix \n",
    "\n",
    "Shows which classes the model is getting confused between.\n",
    "The diagonal should be as dark as possible ‚Äî that means correct predictions.\n",
    "If FSPOT and WSPOT are confused with each other for example, you would see it clearly here.\n",
    "Run Cell 6 first ‚Äî this reads the output from that evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "csv_path = RUNS_DIR / MODEL_NAME / 'results.csv'\n",
    "\n",
    "if not csv_path.exists():\n",
    "    print('Run Cell 4 first.')\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "    plots = [\n",
    "        ('train/box_loss',        'Train Box Loss',    '#e53935'),\n",
    "        ('train/cls_loss',        'Train Class Loss',  '#fb8c00'),\n",
    "        ('val/box_loss',          'Val Box Loss',      '#1e88e5'),\n",
    "        ('val/cls_loss',          'Val Class Loss',    '#00acc1'),\n",
    "        ('metrics/mAP50(B)',      'mAP@0.5',           '#43a047'),\n",
    "        ('metrics/precision(B)',  'Precision',         '#8e24aa'),\n",
    "    ]\n",
    "    for ax, (col, title, colour) in zip(axes.flatten(), plots):\n",
    "        c = col if col in df.columns else col.replace('(B)','')\n",
    "        if c in df.columns:\n",
    "            ax.plot(df['epoch'], df[c], color=colour, linewidth=2)\n",
    "            ax.set_title(title, fontweight='bold')\n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "        else:\n",
    "            ax.set_title(f'{title} (not found)', color='grey')\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Training Progress ‚Äî Spinach Defect Detection', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(REPORTS_DIR / 'training_curves.png', dpi=150)\n",
    "    plt.show()\n",
    "    print('Saved: reports/training_curves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10 ‚Äî Upgrade to a Better Model \n",
    "\n",
    "If the results from Cell 6 are not good enough, this switches to `yolov8s` (small) which is more accurate.\n",
    "It takes around 60‚Äì90 minutes but the improvement is usually noticeable.\n",
    "Change `RUN_UPGRADE` to `True` below and run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# BEST_MODEL = RUNS_DIR / MODEL_NAME / 'weights' / 'best.pt'\n",
    "\n",
    "# MY_IMAGE       = 'BASE_DIR/data/spinach.jpg'\n",
    "# USE_TEST_IMAGE = True   # uses a random image from your test set\n",
    "# # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# if not BEST_MODEL.exists():\n",
    "#     print('Run Cell 4 first.')\n",
    "# else:\n",
    "#     infer_model = YOLO(str(BEST_MODEL))\n",
    "#     if USE_TEST_IMAGE:\n",
    "#         test_imgs = list((SPLITS_DIR / 'test' / 'images').glob('*.*'))\n",
    "#         source = str(random.choice(test_imgs))\n",
    "#         print(f'Using: {source}')\n",
    "#     else:\n",
    "#         source = MY_IMAGE\n",
    "\n",
    "#     results = infer_model.predict(\n",
    "#         source  = source,\n",
    "#         conf    = 0.30,\n",
    "#         imgsz   = IMAGE_SIZE,\n",
    "#         device  = DEVICE,\n",
    "#         verbose = False,\n",
    "#     )\n",
    "\n",
    "#     for result in results:\n",
    "#         ann = cv2.cvtColor(result.plot(), cv2.COLOR_BGR2RGB)\n",
    "#         orig = cv2.cvtColor(cv2.imread(result.path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "#         axes[0].imshow(orig);  axes[0].set_title('Original');    axes[0].axis('off')\n",
    "#         axes[1].imshow(ann);   axes[1].set_title(f'Detections ({len(result.boxes)})'); axes[1].axis('off')\n",
    "#         plt.suptitle('Spinach Defect Detection', fontsize=13, fontweight='bold')\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "\n",
    "#         print(f'\\nDetected {len(result.boxes)} object(s):')   \n",
    "#         for box in result.boxes:\n",
    "#             cls_id = int(box.cls[0])\n",
    "#             print(f'  [{cls_id}] {CLASS_NAMES[cls_id]:<15} confidence: {float(box.conf[0]):.1%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11 ‚Äî Export Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "BEST_MODEL = RUNS_DIR / MODEL_NAME / 'weights' / 'best.pt'\n",
    "\n",
    "if not BEST_MODEL.exists():\n",
    "    print('‚ùå Run Cell 4 first.')\n",
    "else:\n",
    "    m = YOLO(str(BEST_MODEL))\n",
    "    path = m.export(format='onnx', imgsz=IMAGE_SIZE)\n",
    "    print(f'‚úÖ Exported: {path}')\n",
    "    print('\\nTo use this model anywhere:')\n",
    "    print(f'  model = YOLO(\"{BEST_MODEL}\")')\n",
    "    print('  results = model.predict(\"spinach.jpg\", conf=0.3)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spinach_env (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
